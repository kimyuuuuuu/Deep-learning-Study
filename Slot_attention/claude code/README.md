# Slot Attention êµ¬í˜„ ë° í•™ìŠµ

ì´ í”„ë¡œì íŠ¸ëŠ” DeepMindì˜ "Object-Centric Learning with Slot Attention" ë…¼ë¬¸ì„ PyTorchë¡œ êµ¬í˜„í•œ ê²ƒì…ë‹ˆë‹¤.

## ğŸ¯ Slot Attentionì´ë€?

Slot Attentionì€ **ê°ë… í•™ìŠµ ì—†ì´** ì¥ë©´ì„ ì—¬ëŸ¬ ê°ì²´ë¡œ ë¶„í•´í•˜ëŠ” ì–´í…ì…˜ ê¸°ë°˜ ì•„í‚¤í…ì²˜ì…ë‹ˆë‹¤.

### í•µì‹¬ ê°œë…:
- **ìŠ¬ë¡¯(Slot)**: ê° ê°ì²´ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê³ ì • í¬ê¸° ë²¡í„°
- **ê²½ìŸì  ì–´í…ì…˜**: ìŠ¬ë¡¯ë“¤ì´ ì…ë ¥ì˜ ë‹¤ë¥¸ ë¶€ë¶„ì„ 'ì†Œìœ 'í•˜ë ¤ê³  ê²½ìŸ
- **ë°˜ë³µì  ì—…ë°ì´íŠ¸**: ì—¬ëŸ¬ ë¼ìš´ë“œë¥¼ ê±°ì³ ìŠ¬ë¡¯ì„ ê°œì„ 
- **ìˆœì—´ ë“±ë³€ì„±**: ìŠ¬ë¡¯ ìˆœì„œì— ê´€ê³„ì—†ì´ ê°™ì€ ê²°ê³¼

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
Slot_attention/
â”œâ”€â”€ slot_attention.py    # Slot Attention ëª¨ë¸ êµ¬í˜„
â”œâ”€â”€ dataset.py          # ë°ì´í„°ì…‹ ìƒì„± ë° ë¡œë”©
â”œâ”€â”€ train.py           # í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ visualize.py       # ì‹œê°í™” í•¨ìˆ˜ë“¤
â”œâ”€â”€ requirements.txt   # í•„ìš”í•œ íŒ¨í‚¤ì§€ë“¤
â””â”€â”€ README.md         # ì´ íŒŒì¼
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```bash
# ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)
python -m venv slot_attention_env

# ê°€ìƒí™˜ê²½ í™œì„±í™”
# Windows:
slot_attention_env\Scripts\activate
# Linux/Mac:
source slot_attention_env/bin/activate

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt
```

### 2. ê¸°ë³¸ í›ˆë ¨ ì‹¤í–‰

```bash
# ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ í›ˆë ¨ ì‹œì‘
python train.py

# ì»¤ìŠ¤í…€ ì„¤ì •ìœ¼ë¡œ í›ˆë ¨
python train.py --epochs 50 --batch_size 16 --lr 1e-4 --num_slots 5
```

### 3. ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸

```bash
# ë°ì´í„°ì…‹ ìƒì„± í…ŒìŠ¤íŠ¸
python dataset.py

# ì‹œê°í™” í…ŒìŠ¤íŠ¸
python visualize.py
```

## ğŸ”§ ì£¼ìš” ë§¤ê°œë³€ìˆ˜

### ëª¨ë¸ ë§¤ê°œë³€ìˆ˜:
- `num_slots`: ìŠ¬ë¡¯ ê°œìˆ˜ (ê¸°ë³¸ê°’: 7)
- `slot_dim`: ìŠ¬ë¡¯ ì°¨ì› (ê¸°ë³¸ê°’: 64)
- `num_iterations`: ì–´í…ì…˜ ë°˜ë³µ íšŸìˆ˜ (ê¸°ë³¸ê°’: 3)
- `hidden_dim`: ìˆ¨ê²¨ì§„ ë ˆì´ì–´ ì°¨ì› (ê¸°ë³¸ê°’: 64)

### í›ˆë ¨ ë§¤ê°œë³€ìˆ˜:
- `batch_size`: ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 32)
- `learning_rate`: í•™ìŠµë¥  (ê¸°ë³¸ê°’: 4e-4)
- `epochs`: í›ˆë ¨ ì—í­ ìˆ˜ (ê¸°ë³¸ê°’: 100)

## ğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹

### 1. Shapes Dataset (ê¸°ë³¸ ì œê³µ)
```python
from dataset import create_dataloader

train_loader, val_loader = create_dataloader(
    dataset_type='shapes',
    batch_size=32,
    resolution=64,
    max_objects=6,
    min_objects=2
)
```

- **íŠ¹ì§•**: ê¸°í•˜í•™ì  ë„í˜•ë“¤ (ì›, ì‚¬ê°í˜•, ì‚¼ê°í˜•)
- **ì¥ì **: ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥, ë¹ ë¥¸ ì‹¤í—˜
- **ìš©ë„**: ê°œë… ê²€ì¦, ë¹ ë¥¸ í…ŒìŠ¤íŠ¸

### 2. CLEVR-6 Dataset
```python
train_loader, val_loader = create_dataloader(
    dataset_type='clevr6',
    batch_size=32,
    resolution=128
)
```

- **íŠ¹ì§•**: CLEVRì˜ ë‹¨ìˆœí™” ë²„ì „
- **ë‹¤ìš´ë¡œë“œ**: [Multi-Object Datasets](https://github.com/deepmind/multi_object_datasets)

## ğŸ¨ ì‹œê°í™” ì˜ˆì‹œ

### 1. ê¸°ë³¸ ì¬êµ¬ì„± ê²°ê³¼
```python
from visualize import visualize_slots

# ëª¨ë¸ ê²°ê³¼ ì‹œê°í™”
recons, masks, slots, attn = model(images)
fig = visualize_slots(images, recons, masks, save_path='results.png')
```

### 2. ì–´í…ì…˜ ì§„í™” ê³¼ì •
```python
from visualize import visualize_attention_evolution

# ë°˜ë³µë³„ ì–´í…ì…˜ ë³€í™” ì‹œê°í™”
fig = visualize_attention_evolution(attn, save_path='attention_evolution.png')
```

### 3. ìƒì„¸ ìŠ¬ë¡¯ ë¶„í•´
```python
from visualize import visualize_slot_decomposition

# ê°œë³„ ì´ë¯¸ì§€ì˜ ìŠ¬ë¡¯ë³„ ë¶„í•´
fig = visualize_slot_decomposition(
    original_image, reconstructed_image, masks, 
    save_path='decomposition.png'
)
```

## ğŸ“ˆ í›ˆë ¨ ëª¨ë‹ˆí„°ë§

### TensorBoard ì‚¬ìš©
```bash
# í›ˆë ¨ ì¤‘ TensorBoard ì‹¤í–‰
tensorboard --logdir logs

# ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:6006 ì ‘ì†
```

### ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬
```python
# í›ˆë ¨ ì¬ê°œ
python train.py --resume logs/checkpoints/best_model.pth

# íŠ¹ì • ì—í­ì—ì„œ ì¬ê°œ
python train.py --resume logs/checkpoints/checkpoint_epoch_50.pth
```

## ğŸ” ì‹¤í—˜ ê°€ì´ë“œ

### 1. í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •
```bash
# ìŠ¬ë¡¯ ê°œìˆ˜ ì‹¤í—˜
python train.py --num_slots 5   # ê°„ë‹¨í•œ ì¥ë©´
python train.py --num_slots 10  # ë³µì¡í•œ ì¥ë©´

# í•™ìŠµë¥  ì‹¤í—˜
python train.py --lr 1e-4   # ì•ˆì •ì  í•™ìŠµ
python train.py --lr 1e-3   # ë¹ ë¥¸ í•™ìŠµ

# í•´ìƒë„ ì‹¤í—˜
python train.py --resolution 32   # ë¹ ë¥¸ ì‹¤í—˜
python train.py --resolution 128  # ê³ í•´ìƒë„
```

### 2. ë°ì´í„°ì…‹ë³„ ê¶Œì¥ ì„¤ì •

**Shapes Dataset:**
```bash
python train.py --dataset shapes --num_slots 7 --resolution 64 --epochs 100
```

**CLEVR-6 Dataset:**
```bash
python train.py --dataset clevr6 --num_slots 7 --resolution 128 --epochs 200
```

## ğŸ“ í•™ìŠµ íŒ

### 1. ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ê¸° ìœ„í•œ íŒ:
- **ìŠ¬ë¡¯ ê°œìˆ˜**: ì˜ˆìƒ ê°ì²´ ìˆ˜ë³´ë‹¤ ì•½ê°„ ë§ê²Œ ì„¤ì •
- **í•™ìŠµë¥ **: 4e-4ì—ì„œ ì‹œì‘í•´ì„œ í•„ìš”ì‹œ ì¡°ì •
- **ë°°ì¹˜ í¬ê¸°**: GPU ë©”ëª¨ë¦¬ì— ë§ê²Œ ì¡°ì • (16-64 ê¶Œì¥)
- **ì—í­ ìˆ˜**: ì†ì‹¤ì´ ìˆ˜ë ´í•  ë•Œê¹Œì§€ (ë³´í†µ 100-300)

### 2. ë¬¸ì œ í•´ê²°:
- **ìŠ¬ë¡¯ì´ ê°ì²´ë¥¼ ì œëŒ€ë¡œ ë¶„ë¦¬í•˜ì§€ ëª»í•  ë•Œ**: `num_iterations` ì¦ê°€
- **í›ˆë ¨ì´ ë¶ˆì•ˆì •í•  ë•Œ**: í•™ìŠµë¥  ê°ì†Œ, ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ ì ìš©
- **ë©”ëª¨ë¦¬ ë¶€ì¡±**: ë°°ì¹˜ í¬ê¸° ë˜ëŠ” í•´ìƒë„ ê°ì†Œ

### 3. í‰ê°€ ë°©ë²•:
- **ì¬êµ¬ì„± í’ˆì§ˆ**: MSE ì†ì‹¤ í™•ì¸
- **ê°ì²´ ë¶„ë¦¬**: ë§ˆìŠ¤í¬ ì‹œê°í™”ë¡œ í™•ì¸
- **ì¼ê´€ì„±**: ê°™ì€ ê°ì²´ê°€ ê°™ì€ ìŠ¬ë¡¯ì— í• ë‹¹ë˜ëŠ”ì§€ í™•ì¸

## ğŸ“š ì°¸ê³  ìë£Œ

### ë…¼ë¬¸:
- [Object-Centric Learning with Slot Attention](https://arxiv.org/abs/2006.15055) (Locatello et al., 2020)

### ê´€ë ¨ ìë£Œ:
- [Official Implementation](https://github.com/google-research/google-research/tree/master/slot_attention)
- [Multi-Object Datasets](https://github.com/deepmind/multi_object_datasets)

## ğŸ› ë¬¸ì œ ì‹ ê³ 

ë²„ê·¸ë‚˜ ë¬¸ì œê°€ ìˆë‹¤ë©´ GitHub ì´ìŠˆë¥¼ í†µí•´ ì‹ ê³ í•´ì£¼ì„¸ìš”.

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” êµìœ¡ ëª©ì ìœ¼ë¡œ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤. ì›ë³¸ ë…¼ë¬¸ì˜ ë¼ì´ì„ ìŠ¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.

---

**ì¦ê±°ìš´ Slot Attention í•™ìŠµ ë˜ì„¸ìš”! ğŸš€**